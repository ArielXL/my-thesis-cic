\chapter{Estado del arte}

Los avances en redes generativas adversarias (GAN) han habilitado nuevas soluciones en el campo de la imagen médica, particularmente en mamografías. Las GAN, introducidas en 2014, revolucionaron la síntesis de imágenes al enfrentar a un generador contra un discriminador para producir datos fictisios indistinguibles de los reales. Poco después, Mirza y Osindero en \cite{Mirza2014} extendieron este marco con las GAN condicionales (cGAN), permitiendo orientar la generación con información adicional. Este concepto de aprendizaje adversarial condicional sentó las bases para traducir imágenes de entrada en salidas realistas bajo ciertas condiciones.

A partir de esta base teórica, los autores de \cite{Isola2016} presentaron el trabajo \textit{Image-to-Image Translation with Conditional Adversarial Networks}, conocido popularmente como \textit{pix2pix}. Este enfoque demostró que una cGAN con arquitectura tipo U-Net puede traducir imágenes (por ejemplo, de mapas de etiquetas a fotografías o de bocetos a imágenes realistas) mediante un entrenamiento supervisado con pares correspondidos. La novedad de este método radica en tratar la traducción de imágenes como un problema general, utilizando la misma arquitectura y función de pérdida adversarial junto con la función de pérdida de reconstrucción para múltiples tareas, en lugar de diseñar soluciones específicas para cada aplicación. Esto permitió generar imágenes sintéticas de aspecto fotorealista preservando la estructura de la imagen de entrada. En esencia, \textit{pix2pix} resolvió el problema de imágenes borrosas que resultaban de minimizar únicamente pérdidas tradicionales, al introducir una pérdida adversarial que obliga al generador a producir detalles nítidos y realistas. Gracias a este aporte, se estableció un marco genérico de mapeo de pixeles a pixeles aplicable a numerosas tareas de visión por computadora y tuvo un impacto inmediato en imágenes médicas, ya que muchas tareas encajan en este esquema condicional. A pesar de no estar enfocado explícitamente en mamografías, el método de \cite{Isola2016, guan2019} ha sido adoptado y adaptado extensivamente en este dominio, sirviendo como punto de partida obligatorio para los estudios que a continuación se describen. Muchos trabajos posteriores emplean arquitecturas cGAN inspiradas en \textit{pix2pix} o sus derivados (como CycleGAN) para abordar problemas específicos de mamografía, por lo que conviene destacar que el aporte de \cite{Isola2016, rifat2024} marcó un antes y un después al demostrar la eficacia de las redes adversariales condicionales en la traducción de imágenes médicas.

Con el fundamento de \textit{pix2pix} y las cGAN establecido, varios investigadores se enfocaron en generar mamografías sintéticas para paliar la escasez de datos y el desbalance de clases que dificulta los algoritmos de aprendizaje profundo en radiología. Una constante en mamografías es la rara incidencia de casos malignos, lo que genera conjuntos de datos altamente desbalanceados (muchas imágenes normales contra pocas con cáncer) y propensos al sobreajuste. Para enfrentar esto, en \cite{Wu2020} se desarrolló una GAN contextual para síntesis de lesiones mamarias, capaz de insertar o remover lesiones de manera realista en parches de mamografía. Su arquitectura, basada en U-Net \cite{schonfeld2020} con módulos de auto-atención (\textit{self-attention}), recibe como entrada una imagen con contexto de tejido sano e introduce en ella una lesión sintética (o elimina una real), bajo la intuición de que un tumor puede surgir en cualquier lugar del parénquima mamario. A diferencia de generar mamogramas completos desde cero, este enfoque contextual aprovecha las regiones no cancerosas abundantes, modificándolas localmente. El aspecto novedoso es la capacidad de añadir y suprimir tumores en la imagen, conservando la textura circundante de modo coherente. Los autores mostraron que al aumentar el conjunto de entrenamiento con estos parches sintéticos, el rendimiento de un clasificador de ResNet-50 para detección de cáncer en parches mejoró significativamente. En pruebas con datos reales, los resultados aumentaron al incorporar ejemplos sintéticos, evidenciando una mejora estadísticamente significativa en la detección de malignidad. Observaron que existe un límite práctico de hasta un 50\% de datos sintéticos donde la mejora es notable, pero con proporciones mayores el beneficio disminuye, señalando la importancia de equilibrar adecuadamente lo sintético con lo real \cite{kim2022}.

Otro aporte en esta línea es \cite{Shen2021}, Shen y su equipo propusieron la síntesis de masas mamarias con información contextual. Este trabajo busca simular lesiones de mama (masas) de forma diversificada y realista para luego insertarlas en mamogramas sanos, generando mamografías sintéticas anotadas con masas en distintas ubicaciones. El desafío que abordan es que las masas en mamografía presentan gran variabilidad en forma, bordes y contexto (el tejido circundante puede variar mucho), lo que dificulta a una GAN tradicional capturar todos esos factores. En \cite{Shen2021, datta2022} los autores diseñan un esquema donde el generador aprende no solo la distribución visual de la masa, sino también a preservar la consistencia de borde y textura con la mama receptora. Incorporan máscaras de la lesión y características contextuales al proceso adversarial para guiar la inserción plausible de la masa. Como resultados obtienen que entrenando en la base pública DDSM y en datos clínicos del Hospital Nanfang ubicado en China, lograron imágenes sintéticas de masas convincentes, útiles para aumentar datos. Para demostrar que las masas sintetizadas eran visual y funcionalmente convincentes, los autores aplicaron un conjunto de evaluaciones cualitativas y cuantitativas. En primer lugar, realizaron una inspección visual comparando directamente las masas generadas con masas reales, observando que las imágenes sintetizadas reproducían adecuadamente la textura, los contornos y la variabilidad morfológica del tejido patológico, especialmente cuando se incorporaba información contextual de borde. En segundo lugar, emplearon la métrica perceptual LPIPS, que mide la similitud entre dos imágenes utilizando representaciones profundas; los valores obtenidos fueron bajos, lo que indica que las características visuales de las masas generadas son cercanas a las de las imágenes reales \cite{garrucho2023}. Finalmente, evaluaron la utilidad práctica de estas imágenes sintéticas incorporándolas como aumento de datos en una tarea de detección de masas; los resultados mostraron mejoras consistentes en la sensibilidad del detector, evidenciando que las masas producidas no solo son visualmente plausibles, sino también informativas y eficaces para el entrenamiento de modelos de aprendizaje profundo. Más importante, demostraron cuantitativamente que al entrenar un detector de masas con datos aumentados mediante su método, la tasa de detección de lesiones mejoró en un 5 \% respecto a entrenar solo con datos reales. Este incremento de 5 puntos porcentuales subraya que la diversidad adicional de masas generadas ayudó al modelo a generalizar mejor. Así, concluyen que su técnica de síntesis enriquece la diversidad del conjunto de datos (introduciendo variedades de masas difícilmente obtenibles de bases pequeñas) y constituye un primer paso hacia la generación de imágenes mamográficas etiquetadas que fortalezcan tareas de detección y quizás segmentación en el futuro \cite{cheng2024}. No obstante, también reconocen que las imágenes sintetizadas aún no igualan perfectamente la calidad clínica, y mencionan como trabajo futuro extender la idea a otras modalidades médicas con problemas similares de escasez de datos.

La síntesis de mamografías completas para aumentar datos también ha sido explorada. En \cite{Joseph2024, shodiev2025} se presentó un modelo de cGAN guiada por información previa para la generación de mamogramas sintéticos de distintas clases (normal, benigno, maligno), con el fin específico de abordar el desbalance de clases en el conjunto de datos MIAS. Su innovación radica en que el generador puede condicionarse con la etiqueta de clase e incluso entradas específicas para producir variantes múltiples de una mamografía con cierta patología, manteniendo las características anatómicas realistas del tejido mamario. En otras palabras, dado por ejemplo “benigno”, el modelo genera múltiples mamografías diferentes que contienen hallazgos benignos, pero respetando la distribución de texturas de mama. Este enfoque guiado por conocimiento previo (la proporción esperada de tejido denso, la ubicación típica de ciertas lesiones) mejora la fidelidad de las imágenes sintéticas. Como resultados se aprecian que tras generar nuevos ejemplos en las clases minoritarias (benignas y malignas) y agregarlos al entrenamiento, se logró aumentar la precisión de clasificación de cáncer vs sano en aproximadamente 3 \% comparado con entrenar sin aumento de datos (\textit{data augmentation}). Además, reportan que 90 \% de las mamografías sintéticas generadas fueron clasificadas correctamente por un modelo, lo que evidencia alta calidad y coherencia en las imágenes generadas. Este estudio destaca que la incorporación de imágenes cGAN mejora el rendimiento de diagnóstico al aliviar el desequilibrio de datos, y que su método captura bien las características de cada categoría \cite{gui2024}. Como puntos por mejorar, mencionan la necesidad de explorar arquitecturas más complejas o pérdidas perceptuales para eliminar completamente artefactos sutiles y aumentar aún más la resolución de las mamografías generadas, ya que su modelo trabajó con imágenes de tamaño limitado y podría escalarse a resoluciones clínicas.

Un desafío diferente de síntesis se abordó en \cite{Yamazaki2022} con la generación de vistas mamográficas alternativas a partir de una sola vista. En muchos países, el estándar de cribado incluye dos proyecciones por mama mediolateral oblicua (MLO) y craneocaudal (CC) porque cada vista complementa a la otra en la detección de lesiones. Sin embargo, en algunos escenarios históricos o por restricciones se tomaban mamografías de una sola vista, sacrificando información diagnóstica. Los autores, Yamazaki e Ishida, exploraron la generación de vistas mamográficas alternativas a partir de una sola vista, para enriquecer estudios de una sola proyección con la información faltante. Para ello aplican un modelo llamado Complete Representation GAN (CR-GAN) de síntesis de nueva vista (\textit{novel view synthesis}) \cite{pinetz2023}. Incorporaron además dos mejoras técnicas: 

\begin{enumerate}
    \item Crecimiento progresivo de la resolución durante el entrenamiento para estabilizar el aprendizaje de alta resolución.
    \item Pérdida de emparejamiento de características cuyo propósito es imponer que las representaciones internas producidas por el discriminador para una imagen real y su contraparte sintetizada sean lo más similares posible, mejorando así la estabilidad del entrenamiento y la similitud perceptual de las imágenes generadas.
\end{enumerate}

Sus resultados muestran un éxito parcial ya que en varias muestras, el modelo logró generar vistas CC sintéticas plausibles desde MLO, que preservaban estructuras anatómicas principales, ayudando a identificar lesiones que no se veían en la vista original. En particular, reportan que con el esquema propuesto las imágenes CC sintéticas eran más similares a las reales (visualmente y usando las métricas PSNR, SSIM y MS-SSIM) que usando el CR-GAN básico sin adaptaciones \cite{lei2024}. Sin embargo, el desempeño no fue uniforme, o sea, cuando existían microcalcificaciones muy específicas en la mama, la síntesis casi nunca fue satisfactoria, pues estos pequeños detalles son difíciles de regenerar correctamente. Asimismo, reconocen que la resolución y nitidez de las mamografías sintéticas todavía están lejos del nivel clínico necesario. Aunque algunas imágenes generadas parecían realistas, en general la calidad no sería suficiente para reemplazar una toma real aún. Este trabajo, pionero en aplicar síntesis de vistas novedosas en mamografía, sienta una base metodológica valiosa. Demuestra la factibilidad de generar proyecciones mamográficas alternativas con GAN, pero subraya la necesidad de mejorar la fidelidad antes de traducirlo a práctica clínica. Es un primer reporte que abre la puerta a futuras investigaciones para proveer automáticamente la vista complementaria en entornos donde solo se disponga de una vista, lo cual podría aumentar la detección temprana sin requerir mayor radiación al paciente.

En paralelo al desarrollo de técnicas de síntesis para aumento de datos, ha habido avances notables en detección de anomalías en mamografías apoyados por GAN. Una vertiente de investigación busca mejorar los algoritmos de detección utilizando imágenes generadas o transformadas para resaltar la presencia de cáncer. Un ejemplo es el trabajo \cite{Park2023, buades2005}, que aborda la detección no supervisada de cáncer de mama utilizando una GAN de última generación. La idea central es entrenar un modelo generativo únicamente con mamografías normales, de modo que las desviaciones respecto a lo esperado se interpretaran como anomalías. Los autores construyeron un modelo generativo de alta fidelidad con StyleGAN2 entrenado en mamografías sanas, logrando imágenes sintéticas de gran realismo. Posteriormente, desarrollaron un método de detección de anomalías basado en este generador, que dado un estudio nuevo, genera múltiples mamografías normales sintéticas condicionadas que se asemejan a la imagen real y luego comparan la imagen real con estas versiones simuladas libres de cáncer. Las diferencias señaladas en un mapa de discrepancia sirven para localizar posibles lesiones. Aunque este método es completamente no supervisado (no requiere etiquetas de lesión durante entrenamiento), mostró capacidad para distinguir mamografías con cáncer de las normales. En pruebas con 50 casos cancerosos y 50 sanos, lograron una sensibilidad del 78 \% en detectar cáncer de mama, sin embargo, la especificidad fue moderada. Esto indica que el método detecta la mayoría de los cánceres (pocos falsos negativos), pero con bastantes falsos positivos (algunas mastografías normales son marcadas erróneamente como anómalas), algo esperable dado lo desafiante del enfoque sin anotaciones. Los autores enfatizan que, pese a que el desempeño aún no es suficiente para uso clínico por la tasa de falsas alarmas, sus resultados demuestran el potencial del enfoque no supervisado. Este ofrece la ventaja de no depender de grandes conjuntos de datos anotados, y podría seguir mejorándose. Notaron, por ejemplo, que generar múltiples imágenes sintéticas por caso (usaron 9 semillas distintas) mejoró la detección al promedio de una sola, y que ciertos patrones de ruido inusual en las imágenes generadas señalaban limitaciones del generador en áreas de alta complejidad parenquimal. Señalan como trabajo futuro perfeccionar la fidelidad de la GAN para reducir esos artefactos de ruido e incrementar la especificidad del método.

Finalmente, un desarrollo reciente ilustrativo del poder de las GAN en imágenes médicas de mama es \cite{Osuala2025, dorent2023}, quienes exploraron la simulación de realce dinámico de contraste en imágenes de RM de mama usando cGAN. En resonancia magnética de mama, la inyección de medio de contraste es fundamental para resaltar tumores, pero conlleva costos, tiempo e invasividad; además, está contraindicada en ciertas pacientes. La meta de los autores fue entrenar un modelo que pudiera predecir cómo se vería una secuencia de RM con contraste a partir de la imagen sin contraste, permitiendo así efectuar un realce virtual sin necesidad de inyección real. Plantearon el problema como una traducción de imagen condicional (similar a \textit{pix2pix}) desde imágenes pre-contraste a imágenes post-contraste. A diferencia de trabajos previos, buscaron también generar no solo una única fase, sino múltiples puntos temporales del estudio dinámico. Introdujeron un marco de evaluación con métricas llamado SAMe (Scaled Aggregate Measure) para asegurar que las imágenes sintéticas cumplieran con propiedades deseables (fidelidad visual, preservación de la localización de lesiones, consistencia temporal) \cite{Zhang2022, Kingma2014}. Entrenaron su cGAN con un conjunto amplio de datos de RM mamaria con y sin contraste, logrando un modelo capaz de producir secuencias completas. Como resultados demostraron que el modelo podía detectar, localizar y resaltar adecuadamente las lesiones tumorales en las imágenes generadas, de forma comparable a las reales con contraste. Además, evaluaron el beneficio de usar los datos sintéticos en tareas de etapas posteriores y encontraron que los modelos de segmentación aumentados con datos sintéticos eran más robustos ante cambios de dominio. En una prueba, al incluir imágenes sintéticas de contraste en el entrenamiento, la precisión de segmentación en el dominio con contraste aumentó de $0.484$ a $0.663$ (mejora de $0.179$), mientras que el desempeño en el dominio sin contraste se mantuvo prácticamente igual, indicando que el modelo ganó capacidad de generalización sin sacrificar lo ya aprendido. También mostraron que la generación conjunta de las secuencias temporales produjo resultados temporalmente coherentes (el realce progresivo del tumor a lo largo de las fases se reprodujo fielmente). La conclusión de \cite{Osuala2025, kalra2024} es que la inyección de contraste virtual mediante GAN es factible y prometedora, pudiendo en un futuro ayudar en diagnóstico de pacientes donde no se puede administrar contraste. Sus imágenes sintéticas de alta calidad sugieren que en algunos casos se podría detectar y segmentar un tumor sin contraste físico, lo que abreviaría procedimientos. Como innovación, incorporaron un aprendizaje multi-secuencia poco común en la literatura, logrando secuencias completas, y definieron el indicador SAMe para medir objetivamente la calidad de datos sintéticos médicos. Entre los puntos a mejorar, mencionan que si bien las mejoras en segmentación con datos sintéticos fueron modestas en algunos casos, en otros fueron sustanciales, por lo que vale la pena explorar arquitecturas más grandes y especialmente modelos 3D condicionales que tomen en cuenta volúmenes enteros en vez de cortes 2D, lo que podría captar mejor patrones espaciales del realce. También sugieren investigar combinaciones con enfoques de inteligencia artificial explicable para asegurar que el realce virtual no introduzca información errónea. Este trabajo ejemplifica la tendencia de usar GAN para simular procedimientos médicos de forma virtual, reduciendo costos y ampliando posibilidades diagnósticas \cite{Huang2024, choi2024}.

En conclusión, el estado del arte refleja un panorama muy dinámico y prometedor, donde los métodos basados en GAN han pasado de ser una curiosidad técnica a herramientas que superan limitaciones prácticas en mamografía, desde aumentar el escaso repertorio de casos malignos para entrenar mejores detectores, hasta ofrecer nuevas formas de detectar cánceres ocultos y predecir resultados combinando datos heterogéneos. Todo ello impulsado por la idea central de Isola, en \cite{mei2022, Isola2016}, que traduciendo imágenes con redes adversariales podemos resolver de manera uniforme problemas antes abordados. Queda camino por recorrer para su completa adopción clínica, pero los progresos cuantitativos alcanzados sugieren que estas técnicas seguirán madurando. En los próximos años veremos seguramente GANs más refinadas, integradas con otras redes, entrenadas con órdenes de magnitud de más datos, lo que podría llevar a sistemas de ayuda diagnóstica muy potentes. Los investigadores ya identifican mejorar la calidad visual y reducción de artefactos como prioridades inmediatas, así como validaciones con radiólogos en la práctica real. En suma, el estado del arte consolidado indica que las GAN condicionales han abierto nuevas fronteras en la imagen mamaria, potenciando tanto los algoritmos de análisis de imágenes como la extracción de información clínica relevante, con mejoras medibles y claras sobre métodos previos, aunque acompañadas de nuevos desafíos técnicos y éticos a resolver.